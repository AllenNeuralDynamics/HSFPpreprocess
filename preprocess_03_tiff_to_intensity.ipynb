{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from config import load_config\n",
    "paths = load_config(dataset_key='all')\n",
    "from natsort import natsorted\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import itertools\n",
    "import cv2 as cv\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read through each metadata file and fix framestamp rollover\n",
    "metadata_file = glob.glob(os.path.join(paths['raw_data'],'*.csv'))\n",
    "print(metadata_file)\n",
    "\n",
    "numFrames = np.zeros(len(metadata_file))\n",
    "time = []\n",
    "framestamp = []\n",
    "Frames = []\n",
    "for i in range(len(metadata_file)):\n",
    "    metadata = pd.read_csv(metadata_file[i])\n",
    "    numFrames[i] = len(metadata.Width)\n",
    "    numFrames[i] = numFrames[i].astype(int)\n",
    "    timestamp = metadata.CameraTimestampSeconds + 10**-6*metadata.CameraTimestampMicroSeconds\n",
    "    time.append(timestamp)\n",
    "\n",
    "    framestamp = metadata.Framestamp\n",
    "    framestamp = np.array(framestamp)\n",
    "    bitmax = np.where(framestamp == 65535)\n",
    "    if len(bitmax[0]) == 1:\n",
    "        cut = framestamp[bitmax[0][0]+1:-1]\n",
    "        newcut = cut + 65535\n",
    "        Frames.append(np.concatenate((framestamp[0:bitmax[0][0]],newcut)))\n",
    "    elif len(bitmax[0]) > 1:\n",
    "        temp = []\n",
    "        temp.append(np.array(framestamp[0:bitmax[0][0]]))\n",
    "        for j in range(len(bitmax[0])-1):\n",
    "            cut = temp[j][-1] + framestamp[bitmax[0][j]+1:bitmax[0][j+1]]\n",
    "            temp.append(cut)\n",
    "        temp.append(temp[j+1][-1] + framestamp[bitmax[0][-1]+1:-1])\n",
    "        Frames.append(np.concatenate(temp))\n",
    "    elif len(bitmax[0]) == 0:\n",
    "        Frames.append(framestamp[0:-1])\n",
    "\n",
    "width = metadata.Width[0]\n",
    "print(width)\n",
    "Xoffset = metadata.XOffset[0]\n",
    "print(Xoffset)\n",
    "height = metadata.Height[0]\n",
    "print(height)\n",
    "Yoffset = metadata.YOffset[0]\n",
    "print(Yoffset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unskew image, rotation followed by affine transformation\n",
    "\n",
    "# Read from calibration.txt\n",
    "with open(paths['raw_data'] / 'calibration.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        name, value = line.strip().split(' = ')\n",
    "        exec(f'{name} = {value}')\n",
    "\n",
    "# Read from above txt file after running preprocess_01_unskewimage\n",
    "theta_r = rot_tform_thetaR\n",
    "pt1 = [aff_tform_pt1[0]-Xoffset, aff_tform_pt1[1]-Yoffset] \n",
    "pt2 = [aff_tform_pt2[0]-Xoffset, aff_tform_pt2[1]-Yoffset] \n",
    "pt3 = [aff_tform_pt3[0]-Xoffset, aff_tform_pt3[1]-Yoffset] \n",
    "pt4 = [aff_tform_pt4[0]-Xoffset, aff_tform_pt4[1]-Yoffset] \n",
    "pt5 = [aff_tform_pt5[0]-Xoffset, aff_tform_pt5[1]-Yoffset] \n",
    "pt6 = [aff_tform_pt6[0]-Xoffset, aff_tform_pt6[1]-Yoffset]\n",
    "fiber1_location = [fiber1_pixels[1]-Yoffset,fiber1_pixels[0]-Yoffset]\n",
    "fiber2_location = [fiber2_pixels[1]-Yoffset,fiber2_pixels[0]-Yoffset]\n",
    "\n",
    "# Create rotation and affine transformation matrix\n",
    "rows,cols = [height, width]\n",
    "M1 = cv.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),theta_r,1)\n",
    "pts1 = np.float32([pt1, pt2, pt3])\n",
    "pts2 = np.float32([pt4, pt5, pt6])\n",
    "M2 = cv.getAffineTransform(pts1,pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all Tiff directories\n",
    "files = os.listdir(paths['raw_data'])\n",
    "print(files)\n",
    "folders = []\n",
    "for entry in os.scandir(paths['raw_data']):\n",
    "    if entry.is_dir():\n",
    "        folders.append(entry.name)\n",
    "folders = natsorted(folders)\n",
    "print(folders)\n",
    "\n",
    "# Read through each Tiff directory, exrtact tiff files, and unskew images\n",
    "fiber1 = []\n",
    "fiber2 = []\n",
    "peaks = []\n",
    "for i in range(len(folders)):\n",
    "    print(folders[i])\n",
    "    files = os.listdir(os.path.join(paths['raw_data'],folders[i]))\n",
    "    files = natsorted(files)\n",
    "    num_files = np.size(files,0)\n",
    "    tiff_file_path = os.path.join(paths['raw_data'],folders[i],files[0])\n",
    "    temp = io.imread(tiff_file_path).astype(float)\n",
    "    num = int(''.join(filter(str.isdigit, files[-1])))\n",
    "    sz_x = 1000*(math.floor(len(time[i])/1000))\n",
    "    sz_y = width\n",
    "    tempfiber1 = np.zeros([sz_x, sz_y])\n",
    "    tempfiber2 = np.zeros([sz_x, sz_y])\n",
    "    peak = np.zeros(sz_x)\n",
    "    for j in range(math.floor(len(time[i])/1000)):\n",
    "    # for j in range(num_files-1):\n",
    "        print(files[j])\n",
    "        # Extract the number in the filename and convert to integer\n",
    "        num = int(''.join(filter(str.isdigit, files[j])))\n",
    "        tiff_file_path = os.path.join(paths['raw_data'],folders[i],files[j])\n",
    "        temp = io.imread(tiff_file_path).astype(float)\n",
    "        for frame in range(temp.shape[0]):\n",
    "            temp_rotated = cv.warpAffine(temp[frame,:,:],M1,(cols,rows))\n",
    "            img = cv.warpAffine(temp_rotated,M2,(cols,rows))\n",
    "            fiber1_m = np.mean(img[fiber1_location[1]:fiber1_location[0],:],axis=0)\n",
    "            fiber2_m = np.mean(img[fiber2_location[1]:fiber2_location[0],:],axis=0)\n",
    "            \n",
    "            temp_peak, _ = find_peaks(fiber1_m,height=200,distance=200)\n",
    "            if len(temp_peak) > 1:\n",
    "                max_peak = np.argmax(fiber1_m[temp_peak])\n",
    "                temp_peak = temp_peak[max_peak]\n",
    "\n",
    "            fiber1_m = np.expand_dims(fiber1_m, axis=0)\n",
    "            fiber2_m = np.expand_dims(fiber2_m, axis=0)\n",
    "            if j == 0:\n",
    "                tempfiber1[frame,:] = fiber1_m\n",
    "                tempfiber2[frame,:] = fiber2_m\n",
    "                peak[frame] = temp_peak\n",
    "            else:\n",
    "                tempfiber1[num*1000 + frame,:] = fiber1_m\n",
    "                tempfiber2[num*1000 + frame,:] = fiber2_m\n",
    "                peak[num*1000 + frame] = temp_peak\n",
    "\n",
    "    fiber1.append(tempfiber1)\n",
    "    fiber2.append(tempfiber2)\n",
    "    peaks.append(peak)\n",
    "\n",
    "# Truncate time vectors to match the length of tiff files\n",
    "for i in range(len(time)):\n",
    "    if time[i].shape > fiber1[i].shape:\n",
    "        time[i] = time[i][0:fiber1[i].shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set order of lasers and interleave into individual laser channels\n",
    "\n",
    "c = pd.read_hdf(paths['raw_data']/'pixel_to_nm.hdf5', key='Camera_pixel', more='r')\n",
    "w = pd.read_hdf(paths['raw_data']/'pixel_to_nm.hdf5', key='Wavelength_nm', more='r')\n",
    "wavelength = w.to_numpy()\n",
    "camera_px = c.to_numpy()\n",
    "lasers = [405,445,473,514,560]\n",
    "\n",
    "laser_order = []\n",
    "for i in range(len(peaks)):\n",
    "    l_order = np.zeros(len(peaks[i]))\n",
    "    for j in range(len(peaks[i])):\n",
    "        laser_pix = min(camera_px, key=lambda x:abs(x-peaks[i][j]-Xoffset))\n",
    "        camera_pix = np.where(camera_px>laser_pix)\n",
    "        p = camera_pix[-1]\n",
    "        p = p[-1]\n",
    "        temp_laser = min(lasers, key=lambda x:abs(x-wavelength[p]))\n",
    "        l_order[j] = temp_laser\n",
    "    laser_order.append(l_order)\n",
    "print(laser_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interleave signals from each fiber into the five laser channels\n",
    "L405_F1 = []\n",
    "L445_F1 = []\n",
    "L473_F1 = []\n",
    "L514_F1 = []\n",
    "L560_F1 = []\n",
    "L405_F2 = []\n",
    "L445_F2 = []\n",
    "L473_F2 = []\n",
    "L514_F2 = []\n",
    "L560_F2 = []\n",
    "time_405 = []\n",
    "time_445 = []\n",
    "time_473 = []\n",
    "time_514 = []\n",
    "time_560 = []\n",
    "\n",
    "for i in range(len(folders)):\n",
    "    L405_idx = np.where(laser_order[i]==405)\n",
    "    L405_idx = np.array(L405_idx[0])\n",
    "    F1_405 = fiber1[i][L405_idx,:]\n",
    "    F2_405 = fiber2[i][L405_idx,:]\n",
    "    temptime_405 = np.array(time[i][L405_idx])\n",
    "    L445_idx = np.where(laser_order[i]==445)\n",
    "    L445_idx = np.array(L445_idx[0])\n",
    "    F1_445 = fiber1[i][L445_idx,:]\n",
    "    F2_445 = fiber2[i][L445_idx,:]\n",
    "    temptime_445 = np.array(time[i][L445_idx])\n",
    "    L473_idx = np.where(laser_order[i]==473)\n",
    "    L473_idx = np.array(L473_idx[0])\n",
    "    F1_473 = fiber1[i][L473_idx,:]\n",
    "    F2_473 = fiber2[i][L473_idx,:]\n",
    "    temptime_473 = np.array(time[i][L473_idx])\n",
    "    L514_idx = np.where(laser_order[i]==514)\n",
    "    L514_idx = np.array(L514_idx[0])\n",
    "    F1_514 = fiber1[i][L514_idx,:]\n",
    "    F2_514 = fiber2[i][L514_idx,:]\n",
    "    temptime_514 = np.array(time[i][L514_idx])\n",
    "    L560_idx = np.where(laser_order[i]==560)\n",
    "    L560_idx = np.array(L560_idx[0])\n",
    "    F1_560 = fiber1[i][L560_idx,:]\n",
    "    F2_560 = fiber2[i][L560_idx,:]\n",
    "    temptime_560 = np.array(time[i][L560_idx])\n",
    "    \n",
    "    L405_F1.append(F1_405)\n",
    "    L445_F1.append(F1_445)\n",
    "    L473_F1.append(F1_473)\n",
    "    L514_F1.append(F1_514)\n",
    "    L560_F1.append(F1_560)\n",
    "    L405_F2.append(F2_405)\n",
    "    L445_F2.append(F2_445)\n",
    "    L473_F2.append(F2_473)\n",
    "    L514_F2.append(F2_514)\n",
    "    L560_F2.append(F2_560)\n",
    "    time_405.append(temptime_405)\n",
    "    time_445.append(temptime_445)\n",
    "    time_473.append(temptime_473)\n",
    "    time_514.append(temptime_514)\n",
    "    time_560.append(temptime_560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate signals from all frame folders into a single sequence\n",
    "LCh405_F1 = np.concatenate(L405_F1)\n",
    "LCh445_F1 = np.concatenate(L445_F1)\n",
    "LCh473_F1 = np.concatenate(L473_F1)\n",
    "LCh514_F1 = np.concatenate(L514_F1)\n",
    "LCh560_F1 = np.concatenate(L560_F1)\n",
    "LCh405_F2 = np.concatenate(L405_F2)\n",
    "LCh445_F2 = np.concatenate(L445_F2)\n",
    "LCh473_F2 = np.concatenate(L473_F2)\n",
    "LCh514_F2 = np.concatenate(L514_F2)\n",
    "LCh560_F2 = np.concatenate(L560_F2)\n",
    "lasers = np.concatenate(laser_order)\n",
    "timeseries_405 = np.concatenate(time_405)\n",
    "timeseries_445 = np.concatenate(time_445)\n",
    "timeseries_473 = np.concatenate(time_473)\n",
    "timeseries_514 = np.concatenate(time_514)\n",
    "timeseries_560 = np.concatenate(time_560)\n",
    "full_time = np.concatenate(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pixel data into wavelength data\n",
    "\n",
    "LCh_405_F1 = np.zeros([LCh405_F1.shape[0], wavelength.shape[0]])\n",
    "LCh_405_F2 = np.zeros([LCh405_F2.shape[0], wavelength.shape[0]])\n",
    "LCh_445_F1 = np.zeros([LCh445_F1.shape[0], wavelength.shape[0]])\n",
    "LCh_445_F2 = np.zeros([LCh445_F2.shape[0], wavelength.shape[0]])\n",
    "LCh_473_F1 = np.zeros([LCh473_F1.shape[0], wavelength.shape[0]])\n",
    "LCh_473_F2 = np.zeros([LCh473_F2.shape[0], wavelength.shape[0]])\n",
    "LCh_514_F1 = np.zeros([LCh514_F1.shape[0], wavelength.shape[0]])\n",
    "LCh_514_F2 = np.zeros([LCh514_F2.shape[0], wavelength.shape[0]])\n",
    "LCh_560_F1 = np.zeros([LCh560_F1.shape[0], wavelength.shape[0]])\n",
    "LCh_560_F2 = np.zeros([LCh560_F2.shape[0], wavelength.shape[0]])\n",
    "\n",
    "for px in range(0,wavelength.shape[0]):\n",
    "    LCh_405_F1[:,px] = LCh405_F1[:,camera_px[px]-Xoffset]\n",
    "    LCh_405_F2[:,px] = LCh405_F2[:,camera_px[px]-Xoffset]\n",
    "    LCh_445_F1[:,px] = LCh445_F1[:,camera_px[px]-Xoffset]\n",
    "    LCh_445_F2[:,px] = LCh445_F2[:,camera_px[px]-Xoffset]\n",
    "    LCh_473_F1[:,px] = LCh473_F1[:,camera_px[px]-Xoffset]\n",
    "    LCh_473_F2[:,px] = LCh473_F2[:,camera_px[px]-Xoffset]\n",
    "    LCh_514_F1[:,px] = LCh514_F1[:,camera_px[px]-Xoffset]\n",
    "    LCh_514_F2[:,px] = LCh514_F2[:,camera_px[px]-Xoffset]\n",
    "    LCh_560_F1[:,px] = LCh560_F1[:,camera_px[px]-Xoffset]\n",
    "    LCh_560_F2[:,px] = LCh560_F2[:,camera_px[px]-Xoffset]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(6,2))\n",
    "norm_time = timeseries_473 - timeseries_473[0]\n",
    "i = ax.imshow(np.transpose(LCh_473_F1), aspect='auto', vmin=0, vmax=500, extent=[np.min(norm_time), np.max(norm_time), 699, 400])\n",
    "ax.set(xlabel='Time (sec)', ylabel='Wavelength', title='473 nm', ylim=[400,699])\n",
    "ax.grid(False)\n",
    "f.colorbar(i,ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data in hdf5 file\n",
    "\n",
    "data_preprocessed = {'Time_405':timeseries_405, 'Time_445':timeseries_445, 'Time_473':timeseries_473, 'Time_514':timeseries_514, \n",
    "                        'Time_560':timeseries_560, 'Full_TimeStamps':full_time,'Lasers':lasers, 'Wavelength':wavelength, \n",
    "                        'Channel_405_F1':LCh_405_F1, 'Channel_445_F1':LCh_445_F1, 'Channel_473_F1':LCh_473_F1,\n",
    "                        'Channel_514_F1':LCh_514_F1, 'Channel_560_F1':LCh_560_F1, 'Channel_405_F2':LCh_405_F2,\n",
    "                        'Channel_445_F2':LCh_445_F2, 'Channel_473_F2':LCh_473_F2, 'Channel_514_F2':LCh_514_F2,\n",
    "                        'Channel_560_F2':LCh_560_F2}\n",
    "for key in data_preprocessed.keys():\n",
    "    print(f'\\n{key}')\n",
    "    print(data_preprocessed[key])\n",
    "\n",
    "# Write a new hdf5 file with all keys in data_preprocessed\n",
    "hf = h5py.File(paths['raw_data'] / 'hsfp_data_preprocessed.hdf5','w')\n",
    "for key in data_preprocessed.keys():\n",
    "    hf.create_dataset(key, data = data_preprocessed[key])\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a spectrogram image of LCh473_F1 as a check\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(LCh_405_F1.T, aspect='auto', cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(LCh_473_F1.T, aspect='auto', cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(LCh_560_F1.T, aspect='auto', cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('HSFPpreprocess')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a4df223ccf1c5fc7319eec03c370858b4d267606f90f14441b5e052fc959001"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
