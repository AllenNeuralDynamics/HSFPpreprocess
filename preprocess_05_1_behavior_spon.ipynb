{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process step 5\n",
    "- This code aligns spontaneous whisker motion data to simultaneously acquired HSFP data.\n",
    "- Run this code for imaging data acquired during spontaneous behavior.\n",
    "- Needs:\n",
    "    - Run preprocess steps 01, 02, 03, 04\n",
    "    - Loads the hsfp preprocessed data hdf5 file generated in step 03\n",
    "    - Loads behavior event file saved on computer running the dynamic foraging task.\n",
    "- Steps:\n",
    "    - Aligns the hsfp data to harp timestamps by finding the start time on harp.\n",
    "    - For this alignment to work it is essential that the dynamic foraging bonsai task is started first and is acquiring data before hsfp is started.\n",
    "    - Remove bleaching signal with a 4th order polynomial.\n",
    "    - Performs some data visualizations to check quality.\n",
    "    - Correlation analysis between whisker motion and indicator dynamics.\n",
    "    - Indicator signals extracted using specific wavelength ranges. \n",
    "- This is in development. Most of the analysis is playing around with data explorations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from config import load_config\n",
    "paths = load_config(dataset_key='all')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.interpolate import interp1d\n",
    "import csv\n",
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HSFP preprocessed hdf5 file \n",
    "f = h5py.File(paths['raw_data'] / 'fib\\hsfp_data_preprocessed.hdf5','r')\n",
    "time_405 = np.array(f['Time_405'])\n",
    "time_445 = np.array(f['Time_445'])\n",
    "time_473 = np.array(f['Time_473'])\n",
    "time_514 = np.array(f['Time_514'])\n",
    "time_560 = np.array(f['Time_560'])\n",
    "timestamps = np.array(f['Full_TimeStamps'])\n",
    "lasers = np.array(f['Lasers'])\n",
    "wavelength = np.array(f['Wavelength'])\n",
    "L_405_F1 = np.array(f['Channel_405_F1'])\n",
    "L_405_F2 = np.array(f['Channel_405_F2'])\n",
    "L_445_F1 = np.array(f['Channel_445_F1'])\n",
    "L_445_F2 = np.array(f['Channel_445_F2'])\n",
    "L_473_F1 = np.array(f['Channel_473_F1'])\n",
    "L_473_F2 = np.array(f['Channel_473_F2'])\n",
    "L_514_F1 = np.array(f['Channel_514_F1'])\n",
    "L_514_F2 = np.array(f['Channel_514_F2'])\n",
    "L_560_F1 = np.array(f['Channel_560_F1'])\n",
    "L_560_F2 = np.array(f['Channel_560_F2'])\n",
    "# Plot figure with camTrigger \n",
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(timestamps,'.')\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(np.diff(timestamps))\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(np.diff(timestamps))\n",
    "plt.ylim(0,0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read harp event file for the timing input from the hamamatsu camera\n",
    "\n",
    "from datetime import datetime\n",
    "from enum import IntEnum\n",
    "from os import PathLike\n",
    "from typing import Any, BinaryIO, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas._typing import Axes\n",
    "\n",
    "REFERENCE_EPOCH = datetime(1904, 1, 1)\n",
    "\"\"\"The reference epoch for UTC harp time.\"\"\"\n",
    "\n",
    "\n",
    "class MessageType(IntEnum):\n",
    "    \"\"\"Specifies the type of a Harp message.\"\"\"\n",
    "\n",
    "    NA = 0\n",
    "    READ = 1\n",
    "    WRITE = 2\n",
    "    EVENT = 3\n",
    "\n",
    "\n",
    "_SECONDS_PER_TICK = 32e-6\n",
    "_messagetypes = [type.name for type in MessageType]\n",
    "_payloadtypes = {\n",
    "    1: np.dtype(np.uint8),\n",
    "    2: np.dtype(np.uint16),\n",
    "    4: np.dtype(np.uint32),\n",
    "    8: np.dtype(np.uint64),\n",
    "    129: np.dtype(np.int8),\n",
    "    130: np.dtype(np.int16),\n",
    "    132: np.dtype(np.int32),\n",
    "    136: np.dtype(np.int64),\n",
    "    68: np.dtype(np.float32),\n",
    "}\n",
    "\n",
    "def read(\n",
    "    file: Union[str, bytes, PathLike[Any], BinaryIO],\n",
    "    address: Optional[int] = None,\n",
    "    dtype: Optional[np.dtype] = None,\n",
    "    length: Optional[int] = None,\n",
    "    columns: Optional[Axes] = None,\n",
    "    epoch: Optional[datetime] = None,\n",
    "    keep_type: bool = False,\n",
    "):\n",
    "    \"\"\"Read single-register Harp data from the specified file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file\n",
    "        Open file object or filename containing binary data from\n",
    "        a single device register.\n",
    "    address\n",
    "        Expected register address. If specified, the address of\n",
    "        the first message in the file is used for validation.\n",
    "    dtype\n",
    "        Expected data type of the register payload. If specified, the\n",
    "        payload type of the first message in the file is used for validation.\n",
    "    length\n",
    "        Expected number of elements in register payload. If specified, the\n",
    "        payload length of the first message in the file is used for validation.\n",
    "    columns\n",
    "        The optional column labels to use for the data values.\n",
    "    epoch\n",
    "        Reference datetime at which time zero begins. If specified,\n",
    "        the result data frame will have a datetime index.\n",
    "    keep_type\n",
    "        Specifies whether to include a column with the message type.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A pandas data frame containing message data, sorted by time.\n",
    "    \"\"\"\n",
    "    data = np.fromfile(file, dtype=np.uint8)\n",
    "    if len(data) == 0:\n",
    "        return pd.DataFrame(columns=columns, index=pd.Index([], dtype=np.float64, name=\"Time\"))\n",
    "\n",
    "    if address is not None and address != data[2]:\n",
    "        raise ValueError(f\"expected address {address} but got {data[2]}\")\n",
    "\n",
    "    index = None\n",
    "    stride = int(data[1] + 2)\n",
    "    nrows = len(data) // stride\n",
    "    payloadtype = data[4]\n",
    "    payloadoffset = 5\n",
    "    if payloadtype & 0x10 != 0:\n",
    "        seconds = np.ndarray(nrows, dtype=np.uint32, buffer=data, offset=payloadoffset, strides=stride)\n",
    "        payloadoffset += 4\n",
    "        micros = np.ndarray(nrows, dtype=np.uint16, buffer=data, offset=payloadoffset, strides=stride)\n",
    "        payloadoffset += 2\n",
    "        time = micros * _SECONDS_PER_TICK + seconds\n",
    "        payloadtype = payloadtype & ~np.uint8(0x10)\n",
    "        if epoch is not None:\n",
    "            time = epoch + pd.to_timedelta(time, \"s\")  # type: ignore\n",
    "        index = pd.Series(time)\n",
    "        index.name = \"Time\"\n",
    "\n",
    "    payloadsize = stride - payloadoffset - 1\n",
    "    payloadtype = _payloadtypes[payloadtype]\n",
    "    if dtype is not None and dtype != payloadtype:\n",
    "        raise ValueError(f\"expected payload type {dtype} but got {payloadtype}\")\n",
    "\n",
    "    elementsize = payloadtype.itemsize\n",
    "    payloadshape = (nrows, payloadsize // elementsize)\n",
    "    if length is not None and length != payloadshape[1]:\n",
    "        raise ValueError(f\"expected payload length {length} but got {payloadshape[1]}\")\n",
    "\n",
    "    payload = np.ndarray(\n",
    "        payloadshape,\n",
    "        dtype=payloadtype,\n",
    "        buffer=data,\n",
    "        offset=payloadoffset,\n",
    "        strides=(stride, elementsize),\n",
    "    )\n",
    "\n",
    "    result = pd.DataFrame(payload, index=index, columns=columns)\n",
    "    if keep_type:\n",
    "        msgtype = np.ndarray(nrows, dtype=np.uint8, buffer=data, offset=0, strides=stride)\n",
    "        msgtype = pd.Categorical.from_codes(msgtype, categories=_messagetypes)  # type: ignore\n",
    "        result[MessageType.__name__] = msgtype\n",
    "    return result\n",
    "\n",
    "# Read the binary file as a data frame\n",
    "data_frame = read(paths['raw_data'] / 'behavior\\\\raw.harp\\\\BehaviorEvents\\\\Event_32.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the event data to numpy arrays and find the camera trigger start time\n",
    "\n",
    "event_times = np.array(data_frame.index)\n",
    "event_values = np.array(data_frame[0])\n",
    "\n",
    "# Plot the event data\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(event_times, event_values)\n",
    "plt.xlim(event_times[0], event_times[1000])\n",
    "plt.show()\n",
    "\n",
    "print(event_values)\n",
    "d = (np.diff(event_times))\n",
    "print(d)\n",
    "\n",
    "# Define your vector\n",
    "x = d #np.array([0.5, 2.7, 3.99, 2.66, 4.01, 2.66, 4, 2.66, 9, 10, 11])\n",
    "\n",
    "# Define the target pattern with tolerance\n",
    "target_pattern = [0.004, 0.00266, 0.004, 0.00266]\n",
    "tolerance = 0.0001  # Define a tolerance for the matching\n",
    "\n",
    "# Function to check if values match the pattern within tolerance\n",
    "def matches_pattern(sub_array, pattern, tol):\n",
    "    return all(np.isclose(sub_array[i], pattern[i], atol=tol) for i in range(len(pattern)))\n",
    "\n",
    "# Initialize variables for first and last occurrence\n",
    "first_start_index, first_stop_index = None, None\n",
    "last_start_index, last_stop_index = None, None\n",
    "\n",
    "# Loop through the vector to find the first and last occurrences\n",
    "for i in range(len(x) - len(target_pattern) + 1):\n",
    "    # Check if the slice of x matches the pattern within the tolerance\n",
    "    if matches_pattern(x[i:i+len(target_pattern)], target_pattern, tolerance):\n",
    "        # For the first occurrence, set the start and stop indices\n",
    "        if first_start_index is None:\n",
    "            first_start_index = i\n",
    "            first_stop_index = i + len(target_pattern) - 1\n",
    "        # Update the last occurrence each time a match is found\n",
    "        last_start_index = i\n",
    "        last_stop_index = i + len(target_pattern) - 1\n",
    "\n",
    "# Print the results\n",
    "if first_start_index is not None and last_start_index is not None:\n",
    "    print(\"First occurrence of the pattern:\")\n",
    "    print(f\"Start index: {first_start_index}, Stop index: {first_stop_index}\")\n",
    "    print(\"Last occurrence of the pattern:\")\n",
    "    print(f\"Start index: {last_start_index}, Stop index: {last_stop_index}\")\n",
    "else:\n",
    "    print(\"Pattern not found\")\\\n",
    "    \n",
    "camera_trigger_index = first_start_index\n",
    "camera_trigger_time = event_times[camera_trigger_index]\n",
    "print(f\"Camera trigger time: {camera_trigger_time}\")\n",
    "print(f\"Camera trigger time: {camera_trigger_time-event_times[0]} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where the camera trigger is in the harp time\n",
    "\n",
    "# Example: time vector on clock 1 (in seconds, for instance)\n",
    "clock1_times = timestamps  # Replace with your actual clock 1 time vector\n",
    "# Calculate the time differences between consecutive frames on clock 1\n",
    "time_diffs = np.diff(clock1_times)\n",
    "# Start time for clock 2\n",
    "clock2_start_time = camera_trigger_time  # Replace with your actual start time on clock 2\n",
    "# Generate clock 2 times by adding cumulative sum of time differences to start time\n",
    "harp_timestamps = np.insert(np.cumsum(time_diffs), 0, 0) + clock2_start_time\n",
    "print(harp_timestamps)\n",
    "\n",
    "# Generate the timestamp for each laser from the hsfp times\n",
    "\n",
    "def convert_hsfp_to_harp_time(hsfp_timestamps, harp_timestamps, hsfp_time):\n",
    "    \"\"\"\n",
    "    Converts HSFP timestamps to Harp timestamps.\n",
    "    Parameters:\n",
    "    hsfp_timestamps (np.array): The HSFP timestamps.\n",
    "    harp_timestamps (np.array): The Harp timestamps.\n",
    "    hsfp_time (float): The HSFP time to convert.\n",
    "    Returns:\n",
    "    float: The Harp time.\n",
    "    \"\"\"\n",
    "    harp_time = np.zeros(len(hsfp_time))\n",
    "    for i in range(len(hsfp_time)):\n",
    "        # Find the index of the closest HSFP timestamp\n",
    "        hsfp_index = np.searchsorted(hsfp_timestamps, hsfp_time[i])\n",
    "        harp_time[i] = harp_timestamps[hsfp_index]\n",
    "    return harp_time\n",
    "\n",
    "# Convert each laser hsfp time to harp time\n",
    "harp_time_405 = convert_hsfp_to_harp_time(timestamps, harp_timestamps, time_405)\n",
    "harp_time_445 = convert_hsfp_to_harp_time(timestamps, harp_timestamps, time_445)\n",
    "harp_time_473 = convert_hsfp_to_harp_time(timestamps, harp_timestamps, time_473)\n",
    "harp_time_514 = convert_hsfp_to_harp_time(timestamps, harp_timestamps, time_514)\n",
    "harp_time_560 = convert_hsfp_to_harp_time(timestamps, harp_timestamps, time_560)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detrent the hsfp data with a 4th order polynomial\n",
    "\n",
    "def detrend_signal(signal):\n",
    "    x = np.arange(len(signal))\n",
    "    p = np.polyfit(x,signal,5)\n",
    "    y = np.polyval(p,x)\n",
    "    signal_detrended = signal - y + np.mean(signal)\n",
    "    return signal_detrended\n",
    "\n",
    "L_405_F1_detrend = np.zeros(np.shape(L_405_F1))\n",
    "L_405_F2_detrend = np.zeros(np.shape(L_405_F2))\n",
    "L_445_F1_detrend = np.zeros(np.shape(L_445_F1))\n",
    "L_445_F2_detrend = np.zeros(np.shape(L_445_F2))\n",
    "L_473_F1_detrend = np.zeros(np.shape(L_473_F1))\n",
    "L_473_F2_detrend = np.zeros(np.shape(L_473_F2))\n",
    "L_514_F1_detrend = np.zeros(np.shape(L_514_F1))\n",
    "L_514_F2_detrend = np.zeros(np.shape(L_514_F2))\n",
    "L_560_F1_detrend = np.zeros(np.shape(L_560_F1))\n",
    "L_560_F2_detrend = np.zeros(np.shape(L_560_F2))\n",
    "for i in range(len(L_560_F2[0,:])):\n",
    "    L_405_F1_detrend[:,i] = detrend_signal(L_405_F1[:,i])\n",
    "    L_405_F2_detrend[:,i] = detrend_signal(L_405_F2[:,i])\n",
    "    L_445_F1_detrend[:,i] = detrend_signal(L_445_F1[:,i])\n",
    "    L_445_F2_detrend[:,i] = detrend_signal(L_445_F2[:,i])\n",
    "    L_473_F1_detrend[:,i] = detrend_signal(L_473_F1[:,i])\n",
    "    L_473_F2_detrend[:,i] = detrend_signal(L_473_F2[:,i])\n",
    "    L_514_F1_detrend[:,i] = detrend_signal(L_514_F1[:,i])\n",
    "    L_514_F2_detrend[:,i] = detrend_signal(L_514_F2[:,i])\n",
    "    L_560_F1_detrend[:,i] = detrend_signal(L_560_F1[:,i])\n",
    "    L_560_F2_detrend[:,i] = detrend_signal(L_560_F2[:,i])\n",
    "\n",
    "# Calculate z-scores for each detrended trace\n",
    "z_405_F1 = (L_405_F1_detrend - np.mean(L_405_F1_detrend,axis=0))/np.std(L_405_F1_detrend,axis=0)\n",
    "z_405_F2 = (L_405_F2_detrend - np.mean(L_405_F2_detrend,axis=0))/np.std(L_405_F2_detrend,axis=0)\n",
    "z_445_F1 = (L_445_F1_detrend - np.mean(L_445_F1_detrend,axis=0))/np.std(L_445_F1_detrend,axis=0)\n",
    "z_445_F2 = (L_445_F2_detrend - np.mean(L_445_F2_detrend,axis=0))/np.std(L_445_F2_detrend,axis=0)\n",
    "z_473_F1 = (L_473_F1_detrend - np.mean(L_473_F1_detrend,axis=0))/np.std(L_473_F1_detrend,axis=0)\n",
    "z_473_F2 = (L_473_F2_detrend - np.mean(L_473_F2_detrend,axis=0))/np.std(L_473_F2_detrend,axis=0)\n",
    "z_514_F1 = (L_514_F1_detrend - np.mean(L_514_F1_detrend,axis=0))/np.std(L_514_F1_detrend,axis=0)\n",
    "z_514_F2 = (L_514_F2_detrend - np.mean(L_514_F2_detrend,axis=0))/np.std(L_514_F2_detrend,axis=0)\n",
    "z_560_F1 = (L_560_F1_detrend - np.mean(L_560_F1_detrend,axis=0))/np.std(L_560_F1_detrend,axis=0)\n",
    "z_560_F2 = (L_560_F2_detrend - np.mean(L_560_F2_detrend,axis=0))/np.std(L_560_F2_detrend,axis=0)\n",
    "\n",
    "# # Calculate deltaF/F for each detrended trace\n",
    "# dF_F_405_F1 = ((L_405_F1_detrend/np.mean(L_405_F1_detrend,axis=0))-1)*100\n",
    "# dF_F_405_F2 = ((L_405_F2_detrend/np.mean(L_405_F2_detrend,axis=0))-1)*100\n",
    "# dF_F_445_F1 = ((L_445_F1_detrend/np.mean(L_445_F1_detrend,axis=0))-1)*100\n",
    "# dF_F_445_F2 = ((L_445_F2_detrend/np.mean(L_445_F2_detrend,axis=0))-1)*100\n",
    "# dF_F_473_F1 = ((L_473_F1_detrend/np.mean(L_473_F1_detrend,axis=0))-1)*100\n",
    "# dF_F_473_F2 = ((L_473_F2_detrend/np.mean(L_473_F2_detrend,axis=0))-1)*100\n",
    "# dF_F_514_F1 = ((L_514_F1_detrend/np.mean(L_514_F1_detrend,axis=0))-1)*100\n",
    "# dF_F_514_F2 = ((L_514_F2_detrend/np.mean(L_514_F2_detrend,axis=0))-1)*100\n",
    "# dF_F_560_F1 = ((L_560_F1_detrend/np.mean(L_560_F1_detrend,axis=0))-1)*100\n",
    "# dF_F_560_F2 = ((L_560_F2_detrend/np.mean(L_560_F2_detrend,axis=0))-1)*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spectrogram of wavelength over time\n",
    "\n",
    "# plt.figure(figsize=(10,3))\n",
    "# t = harp_time_560-harp_time_560[0]\n",
    "# plt.imshow(np.transpose(dF_F_560_F2),aspect='auto',cmap='Reds',vmin=-5,vmax=5,extent=[t[0],t[-1],700,400])\n",
    "# plt.colorbar()\n",
    "# plt.xlabel('Time (sec)')\n",
    "# plt.ylabel('Wavelength (nm)')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "t = harp_time_560-harp_time_560[0]\n",
    "plt.imshow(np.transpose(z_560_F2),aspect='auto',cmap='Reds',vmin=-2,vmax=2,extent=[t[0],t[-1],700,400])\n",
    "plt.colorbar()\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Wavelength (nm)')\n",
    "plt.title('z-score, Ex: 560 nm')\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(harp_time_560-harp_time_560[0],z_560_F1[:,600-400])\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('z-score')\n",
    "plt.title('z-score, Ex: 560 nm')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out ranges for indicator data\n",
    "\n",
    "Ca_F1 = np.mean(z_473_F1[:,490-400:505-400], axis=1)\n",
    "Ca_F2 = np.mean(z_473_F2[:,490-400:505-400], axis=1)\n",
    "Ach_F1 = np.mean(z_514_F1[:,525-400:535-400], axis=1)\n",
    "Ach_F2 = np.mean(z_514_F2[:,525-400:535-400], axis=1)\n",
    "Da_F1 = np.mean(z_560_F1[:,590-400:610-400], axis=1)\n",
    "Da_F2 = np.mean(z_560_F2[:,590-400:610-400], axis=1)\n",
    "\n",
    "# Plot indicator data\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(harp_time_473-harp_time_473[0],Ca_F1)\n",
    "plt.plot(harp_time_473-harp_time_473[0],Ca_F2)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('z-score')\n",
    "plt.title('z-score, Ca indicator')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(harp_time_514-harp_time_514[0],Ach_F1)\n",
    "plt.plot(harp_time_514-harp_time_514[0],Ach_F2)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('z-score')\n",
    "plt.title('z-score, Ach indicator')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(harp_time_560-harp_time_560[0],Da_F1)\n",
    "plt.plot(harp_time_560-harp_time_560[0],Da_F2)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('z-score')\n",
    "plt.title('z-score, Da indicator')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load behavior data video data\n",
    "\n",
    "# Load behavior timestamps\n",
    "behavior_time_path = [paths['raw_data'] / 'behavior-videos\\side_camera_right.csv']\n",
    "timestamps = np.genfromtxt(behavior_time_path[0], delimiter=',', dtype=None, encoding=None)\n",
    "behavior_time = timestamps['f0']\n",
    "\n",
    "# Load motion data\n",
    "motion_path = [paths['raw_data'] / 'fib\\whisker_motion.csv']\n",
    "motion_data = np.genfromtxt(motion_path[0], delimiter=',', dtype=None, encoding=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot motion data\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(behavior_time, motion_data)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Motion')\n",
    "plt.title('Motion data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the motion data to match the harp time\n",
    "\n",
    "def downsample_motion_data(behavior_time, motion_data, harp_time):\n",
    "    \"\"\"\n",
    "    Downsamples the motion data to match the harp time.\n",
    "    Parameters:\n",
    "    behavior_time (np.array): The behavior timestamps.\n",
    "    motion_data (np.array): The motion data.\n",
    "    harp_time (np.array): The harp timestamps.\n",
    "    Returns:\n",
    "    np.array: The downsampled motion data.\n",
    "    \"\"\"\n",
    "    # Interpolate the motion data\n",
    "    f = interp1d(behavior_time, motion_data, kind='linear')\n",
    "    motion_data_downsampled = f(harp_time)\n",
    "    return motion_data_downsampled\n",
    "\n",
    "motion_data_downsampled = downsample_motion_data(behavior_time, motion_data, harp_time_560)\n",
    "\n",
    "# Plot the downsampled motion data\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(behavior_time, motion_data)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Motion')\n",
    "plt.title('Motion data')\n",
    "plt.ylim(0,1000)\n",
    "#plt.xlim(514250,514500)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(harp_time_560, motion_data_downsampled)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Motion')\n",
    "plt.title('Downsampled motion data')\n",
    "plt.ylim(0,1000)\n",
    "#plt.xlim(514250,514500)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Low pass filter the motion data\n",
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def low_pass_filter(data, cutoff_freq, fs):\n",
    "    \"\"\"\n",
    "    Applies a low-pass filter to the data.\n",
    "    Parameters:\n",
    "    data (np.array): The data to filter.\n",
    "    cutoff_freq (float): The cutoff frequency for the filter.\n",
    "    fs (float): The sampling frequency.\n",
    "    Returns:\n",
    "    np.array: The filtered data.\n",
    "    \"\"\"\n",
    "    # Normalize the cutoff frequency\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    # Apply the filter\n",
    "    b, a = butter(4, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "motion_data_filtered = low_pass_filter(motion_data_downsampled, 5, 30.5)\n",
    "\n",
    "# Plot the filtered motion data\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(harp_time_560, motion_data_filtered)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Motion')\n",
    "plt.title('Filtered motion data')\n",
    "plt.ylim(0,1000)\n",
    "#plt.xlim(514250,514500)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot motion data with indicators\n",
    "\n",
    "# set figure size\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=True, figsize=(14,8), gridspec_kw={'hspace': 0})  # hspace=0 removes vertical space\n",
    "\n",
    "ax1.plot(harp_time_560-harp_time_560[0], motion_data_filtered, color='black')\n",
    "# Remove x-axis from the first plot to avoid duplicate x-axis labels\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "#ax1.get_yaxis().set_visible(False)\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax1.set_ylabel('Whisking')\n",
    "\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.plot(harp_time_473-harp_time_473[0],Ca_F1,color='#1f77b4')\n",
    "ax2.get_xaxis().set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['bottom'].set_visible(False)\n",
    "ax2.set_ylabel('Z-score')\n",
    "\n",
    "ax3.plot(harp_time_514-harp_time_514[0],Ach_F1,color='#2ca02c')\n",
    "ax3.get_xaxis().set_visible(False)\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.spines['bottom'].set_visible(False)\n",
    "ax3.set_ylabel('Z-score')\n",
    "\n",
    "ax4.plot(harp_time_560-harp_time_560[0],Da_F1,color='#e34a33')\n",
    "ax4.spines['top'].set_visible(False)\n",
    "ax4.set_xlabel('Time (sec)')\n",
    "ax4.set_ylabel('Z-score')\n",
    "\n",
    "ax1.set_ylim(0, 500)\n",
    "# for ax in (ax2, ax3, ax4):\n",
    "#     ax.set_ylim(-3, 4)\n",
    "for ax in (ax1, ax2, ax3, ax4):\n",
    "    ax.set_xlim(400, 600)\n",
    "\n",
    "# Adjust layout to remove any extra margin around the subplots\n",
    "#plt.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot motion data with indicators\n",
    "\n",
    "# set figure size\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(14,4), gridspec_kw={'hspace': 0})  # hspace=0 removes vertical space\n",
    "\n",
    "ax1.plot(harp_time_560-harp_time_560[0], motion_data_filtered, color='black')\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.plot(harp_time_473-harp_time_473[0],Ca_F1,color='#1f77b4')\n",
    "ax2.plot(harp_time_514-harp_time_514[0],Ach_F1,color='#2ca02c')\n",
    "ax2.plot(harp_time_560-harp_time_560[0],Da_F1,color='#e34a33')\n",
    "\n",
    "# ax1.set_ylim(0, 500)\n",
    "# for ax in (ax1, ax2):\n",
    "#     ax.set_ylim(-3, 4.5)\n",
    "# for ax in (ax1, ax2):\n",
    "#     ax.set_xlim(1370, 1620)\n",
    "ax2.set_xlabel('Time (sec)')\n",
    "ax2.set_ylabel('Z-score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between motion and indicators\n",
    "\n",
    "# Remove outlier motion values\n",
    "\n",
    "motion_data_filtered[motion_data_filtered > 1000] = 500\n",
    "\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def calculate_correlation(motion_data, indicator_data):\n",
    "    \"\"\"\n",
    "    Calculates the correlation between motion and indicator data.\n",
    "    Parameters:\n",
    "    motion_data (np.array): The motion data.\n",
    "    indicator_data (np.array): The indicator data.\n",
    "    Returns:\n",
    "    float: The correlation coefficient.\n",
    "    \"\"\"\n",
    "    correlation, _ = pearsonr(motion_data, indicator_data)\n",
    "    return correlation\n",
    "\n",
    "start = 0\n",
    "stop = 48000\n",
    "whisking = motion_data_filtered[start:stop]/np.mean(motion_data_filtered[start:stop])\n",
    "correlation_Ca = calculate_correlation(whisking, Ca_F2[start:stop])\n",
    "correlation_Ach = calculate_correlation(whisking, Ach_F2[start:stop])\n",
    "correlation_Da = calculate_correlation(whisking, Da_F2[start:stop])\n",
    "\n",
    "print(f\"Correlation between motion and Ca indicator: {correlation_Ca}\")\n",
    "print(f\"Correlation between motion and Ach indicator: {correlation_Ach}\")\n",
    "print(f\"Correlation between motion and Da indicator: {correlation_Da}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-correlation between motion and indicators\n",
    "\n",
    "# Calculate the cross correlation between Ca, Ach, and Da\n",
    "\n",
    "from scipy.signal import correlate\n",
    "\n",
    "# Calculate the cross-correlation between motion and Ca\n",
    "cross_corr_Ca = correlate(motion_data_filtered/np.mean(motion_data_filtered), Ca_F2, mode='full')\n",
    "n = len(Ca_F1)\n",
    "cross_corr_Ca = cross_corr_Ca / n\n",
    "# Calculate the cross-correlation between motion and Ach\n",
    "cross_corr_Ach = correlate(motion_data_filtered/np.mean(motion_data_filtered), Ach_F2, mode='full')\n",
    "n = len(Ach_F1)\n",
    "cross_corr_Ach = cross_corr_Ach / n\n",
    "# Calculate the cross-correlation between motion and Da\n",
    "cross_corr_Da = correlate(motion_data_filtered/np.mean(motion_data_filtered), Da_F2, mode='full')\n",
    "n = len(Da_F1)\n",
    "cross_corr_Da = cross_corr_Da / n\n",
    "\n",
    "# Plot the cross-correlation results over time lags\n",
    "plt.figure(figsize=(5, 3))\n",
    "# Create a time vector for the cross-correlation results\n",
    "lags = np.arange(-len(cross_corr_Ca)//2+1, len(cross_corr_Ca)//2+1)\n",
    "delta_t = 1 / 30.05  # Sampling interval\n",
    "lag_times = lags * delta_t\n",
    "plt.plot(lag_times, cross_corr_Ca, label='Whisking vs Ca', color='blue')\n",
    "lags = np.arange(-len(cross_corr_Ach)//2+1, len(cross_corr_Ach)//2+1)\n",
    "lag_times = lags * delta_t\n",
    "plt.plot(lag_times, cross_corr_Ach, label='Whisking vs Ach', color='green')\n",
    "lags = np.arange(-len(cross_corr_Da)//2+1, len(cross_corr_Da)//2+1)\n",
    "lag_times = lags * delta_t\n",
    "plt.plot(lag_times, cross_corr_Da, label='Whisking vs Da', color='red')\n",
    "plt.xlabel('Time Lag (s)')\n",
    "plt.ylabel('Cross-Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim(-10, 10)\n",
    "plt.ylim(-1, 1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cross correlation between Ca, Ach, and Da\n",
    "\n",
    "from scipy.signal import correlate\n",
    "\n",
    "# Calculate the cross-correlation between Ca and Ach\n",
    "cross_corr_Ca_Ach = correlate(Ca_F2, Ach_F2, mode='full')\n",
    "n = len(Ca_F2)\n",
    "cross_corr_Ca_Ach = cross_corr_Ca_Ach / n\n",
    "# Calculate the cross-correlation between Ca and Da\n",
    "cross_corr_Ca_Da = correlate(Ca_F2, Da_F2, mode='full')\n",
    "n = len(Ca_F2)\n",
    "cross_corr_Ca_Da = cross_corr_Ca_Da / n\n",
    "# Calculate the cross-correlation between Ach and Da\n",
    "cross_corr_Ach_Da = correlate(Ach_F2, Da_F2, mode='full')\n",
    "n = len(Ach_F2)\n",
    "cross_corr_Ach_Da = cross_corr_Ach_Da / n\n",
    "\n",
    "# Plot the cross-correlation results over time lags\n",
    "plt.figure(figsize=(5, 3))\n",
    "# Create a time vector for the cross-correlation results\n",
    "lags = np.arange(-len(cross_corr_Ca_Ach)//2+1, len(cross_corr_Ca_Ach)//2+1)\n",
    "delta_t = 1 / 30.05  # Sampling interval\n",
    "lag_times = lags * delta_t\n",
    "plt.plot(lag_times, cross_corr_Ca_Ach, label='Ca vs Ach', color='purple')\n",
    "lags = np.arange(-len(cross_corr_Ca_Da)//2+1, len(cross_corr_Ca_Da)//2+1)\n",
    "lag_times = lags * delta_t\n",
    "plt.plot(lag_times, cross_corr_Ca_Da, label='Ca vs Da', color='teal')\n",
    "lags = np.arange(-len(cross_corr_Ach_Da)//2+1, len(cross_corr_Ach_Da)//2+1)\n",
    "lag_times = lags * delta_t\n",
    "plt.plot(lag_times, cross_corr_Ach_Da, label='Ach vs Da', color='orange')\n",
    "plt.xlabel('Time Lag (s)')\n",
    "plt.ylabel('Cross-Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim(-10, 10)\n",
    "plt.ylim(-0.6, 0.6)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load TTL file and timestamp csv from NIDAQ\n",
    "\n",
    "# TTL_file = glob.glob(os.path.join(paths['raw_data'],'TTL*'))\n",
    "# print(TTL_file)\n",
    "\n",
    "# # Timestamp for TTL    \n",
    "# with open(TTL_file[1]) as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     datatemp = np.array([row for row in reader])\n",
    "#     TTLts = datatemp[0:,:].astype(np.float32)\n",
    "\n",
    "# TTL_signal = np.fromfile(TTL_file[0])\n",
    "\n",
    "# # Split the TTL signal into its individual sources\n",
    "# TTL_signal1 = TTL_signal[0::3] # Camera timing signal\n",
    "# TTL_signal2 = TTL_signal[1::3] # Teensy trigger signal\n",
    "# TTL_signal3 = TTL_signal[2::3] # Harp behavior signal\n",
    "\n",
    "# # Binarize the TTL signal\n",
    "# TTL_signal1 = np.where(TTL_signal1 > 3, 1, 0)\n",
    "# TTL_signal2 = np.where(TTL_signal2 > 3, 1, 0)\n",
    "# TTL_signal3 = np.where(TTL_signal3 > 1, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the time stamps of the camera frames\n",
    "\n",
    "# def get_rising_edges_and_lengths(signal):\n",
    "#     \"\"\"\n",
    "#     Get the indices of rising edges and the lengths of the high (1) periods in a TTL signal.\n",
    "\n",
    "#     Parameters:\n",
    "#     signal (list or np.array): The binary TTL signal (0s and 1s).\n",
    "\n",
    "#     Returns:\n",
    "#     np.array: Indices of rising edges.\n",
    "#     np.array: Lengths of the high (1) periods.\n",
    "#     \"\"\"\n",
    "#     # Ensure the input signal is a numpy array\n",
    "#     signal = np.array(signal)\n",
    "#     # Find the difference between consecutive elements\n",
    "#     diff = np.diff(signal)\n",
    "#     # Rising edges are where the difference is 1 (0 -> 1 transition)\n",
    "#     rising_edges = np.where(diff == 1)[0] + 1  # Add 1 to match original index\n",
    "#     # Falling edges are where the difference is -1 (1 -> 0 transition)\n",
    "#     falling_edges = np.where(diff == -1)[0] + 1  # Add 1 to match original index\n",
    "#     # Handle the case where the signal ends with a high level (i.e., no falling edge at the end)\n",
    "#     if signal[-1] == 1:\n",
    "#         falling_edges = np.append(falling_edges, len(signal))\n",
    "#     # Calculate the lengths of the high periods\n",
    "#     high_lengths = falling_edges - rising_edges\n",
    "\n",
    "#     return rising_edges, falling_edges, high_lengths\n",
    "\n",
    "# def upsample_timestamps(timestamps, data_length, downsample_factor=1000):\n",
    "#     \"\"\"\n",
    "#     Upsamples the timestamp vector to match the length of the data vector.\n",
    "\n",
    "#     Parameters:\n",
    "#     timestamps (list or np.array): The downsampled timestamps (1 value for every 1000 data points).\n",
    "#     data_length (int): The length of the data vector.\n",
    "#     downsample_factor (int): The downsampling factor, default is 1000 (timestamps every 1000 data points).\n",
    "\n",
    "#     Returns:\n",
    "#     np.array: The upsampled timestamp vector.\n",
    "#     \"\"\"\n",
    "#     # Generate the original downsampled indices (one timestamp for every downsample_factor data points)\n",
    "#     original_indices = np.arange(0, data_length, downsample_factor)\n",
    "#     # Create an array of indices for the full data length\n",
    "#     full_indices = np.arange(data_length)\n",
    "#     # Perform linear interpolation to upsample the timestamps\n",
    "#     interpolation_function = interp1d(original_indices, timestamps, kind='linear', fill_value=\"extrapolate\")\n",
    "#     # Apply the interpolation function to get timestamps for each data point\n",
    "#     upsampled_timestamps = interpolation_function(full_indices)\n",
    "    \n",
    "#     return upsampled_timestamps\n",
    "\n",
    "# # Get rising edges and lengths of high periods\n",
    "# TTL_signal1_rising, TTL_signal1_falling, TTL_signal1_lengths = get_rising_edges_and_lengths(TTL_signal1)\n",
    "\n",
    "# # Get rising edges that have length between 19 and 21\n",
    "# TTL_signal1_rising = TTL_signal1_rising[TTL_signal1_lengths >= 19]\n",
    "# TTL_signal1_lengths = TTL_signal1_lengths[TTL_signal1_lengths >= 19]\n",
    "# TTL_signal1_rising = TTL_signal1_rising[TTL_signal1_lengths <= 21]\n",
    "# TTL_signal1_lengths = TTL_signal1_lengths[TTL_signal1_lengths <= 21]\n",
    "\n",
    "# # Upsample the timestamps\n",
    "# upsampled_timestamps = upsample_timestamps(TTLts[:,0], len(TTL_signal1), downsample_factor=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Digitize the harp analog signal\n",
    "\n",
    "# def digitize_signal(signal, timestamps, threshold):\n",
    "#     # Determine transitions based on the threshold\n",
    "#     high = signal > threshold\n",
    "#     transitions = np.diff(high.astype(int))\n",
    "    \n",
    "#     # Find the indices of transition points\n",
    "#     low_to_high_indices = np.where(transitions == 1)[0] + 1  # Low to High transition (0 -> 1)\n",
    "#     high_to_low_indices = np.where(transitions == -1)[0] + 1  # High to Low transition (1 -> 0)\n",
    "    \n",
    "#     # Store the transitions with timestamps and types\n",
    "#     transition_points = {\n",
    "#         \"timestamp\": [],\n",
    "#         \"transition\": []  # 1 for low->high, 0 for high->low\n",
    "#     }\n",
    "    \n",
    "#     for idx in low_to_high_indices:\n",
    "#         transition_points[\"timestamp\"].append(timestamps[idx])\n",
    "#         transition_points[\"transition\"].append(1)  # Low to High\n",
    "    \n",
    "#     for idx in high_to_low_indices:\n",
    "#         transition_points[\"timestamp\"].append(timestamps[idx])\n",
    "#         transition_points[\"transition\"].append(0)  # High to Low\n",
    "    \n",
    "#     return transition_points\n",
    "\n",
    "# transition_points = digitize_signal(TTL_signal3, upsampled_timestamps, 0.5)\n",
    "\n",
    "# # Sort the transitions and timestamps\n",
    "# sorted_indices = np.argsort(transition_points[\"timestamp\"])\n",
    "# sorted_timestamps = np.array(transition_points[\"timestamp\"])[sorted_indices]\n",
    "# sorted_transitions = np.array(transition_points[\"transition\"])[sorted_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the transitions\n",
    "\n",
    "# plt.figure(figsize=(8,3))\n",
    "# plt.plot(upsampled_timestamps, TTL_signal3)\n",
    "# plt.scatter(transition_points[\"timestamp\"], np.ones(len(transition_points[\"timestamp\"])), c=transition_points[\"transition\"], cmap='coolwarm')\n",
    "# plt.xlim(upsampled_timestamps[0], upsampled_timestamps[6500])\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(8,3))\n",
    "# plt.plot(sorted_timestamps)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read harp barcode collected on nidaq\n",
    "\n",
    "# import numpy as np\n",
    "# import warnings\n",
    "\n",
    "# def align_timestamps_to_anchor_points(timestamps_to_align, start_times, anchor_times):\n",
    "#     \"\"\"\n",
    "#     Aligns a set of timestamps to anchor points (e.g., Harp clock times)\n",
    "\n",
    "#     We assume these timestamps are acquired by a system that is\n",
    "#     not aligned to the Harp clock. This function finds the nearest\n",
    "#     anchor point in the Harp clock for each timestamp, and then\n",
    "#     interpolates between the anchor points to align the timestamps.\n",
    "\n",
    "#     `decode_harp_clock` must be run first, in order to find the\n",
    "#     start of each second in the Harp clock.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     timestamps_to_align : np.array\n",
    "#         Local timestamps (in seconds) to align to the Harp clock\n",
    "#     start_times : np.array\n",
    "#         Local start times of each second in the Harp clock\n",
    "#         (output by `decode_harp_clock`)\n",
    "#     anchor_times : np.array\n",
    "#         Global clock times in seconds (typically the Harp clock times,\n",
    "#         but can be any set of anchor points to align to)\n",
    "#         (output by `decode_harp_clock`)\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     aligned_times : np.array\n",
    "#         Aligned timestamps\n",
    "#     \"\"\"\n",
    "\n",
    "#     if len(start_times) != len(anchor_times):\n",
    "#         raise ValueError(\n",
    "#             \"The number of start times must equal the number of Harp times\"\n",
    "#         )\n",
    "\n",
    "#     N = len(start_times)\n",
    "\n",
    "#     slopes = np.zeros((N + 1,))\n",
    "#     offsets = np.zeros((N + 1,))\n",
    "\n",
    "#     # compute overall slope and offset\n",
    "#     A = np.vstack([start_times, np.ones(len(start_times))]).T\n",
    "#     slopes[0], offsets[0] = np.linalg.lstsq(A, anchor_times, rcond=None)[0]\n",
    "\n",
    "#     # compute slope and offset for each segment\n",
    "#     for i in range(N):\n",
    "#         x = start_times[i : i + 2]\n",
    "#         y = anchor_times[i : i + 2]\n",
    "#         A = np.vstack([x, np.ones(len(x))]).T\n",
    "#         slopes[i + 1], offsets[i + 1] = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "\n",
    "#     # find the nearest anchor point for each timestamp to align\n",
    "#     nearest = np.searchsorted(start_times, timestamps_to_align, side=\"left\")\n",
    "\n",
    "#     nearest[nearest == N] = 0\n",
    "\n",
    "#     # interpolate between the anchor points\n",
    "#     aligned_times = timestamps_to_align * slopes[nearest] + offsets[nearest]\n",
    "\n",
    "#     return aligned_times\n",
    "\n",
    "\n",
    "# def decode_harp_clock(timestamps, states, baud_rate=1000.0):\n",
    "#     \"\"\"\n",
    "#     Decodes Harp clock times (in seconds) from a sequence of local\n",
    "#     event timestamps and states.\n",
    "\n",
    "#     The Harp Behavior board can be configured to output a digital\n",
    "#     signal that encodes the current Harp time as a 32-bit integer,\n",
    "#     which is emitted once per second.\n",
    "\n",
    "#     The format of the signal is as follows:\n",
    "\n",
    "#       Default value: high\n",
    "#       Start bit: low -- indicates the transition to the next second\n",
    "#       8 bits: byte 0, with least significant bit first\n",
    "#       2 bits: high / low transition\n",
    "#       8 bits: byte 1, with least significant bit first\n",
    "#       2 bits: high / low transition\n",
    "#       8 bits: byte 2, with least significant bit first\n",
    "#       2 bits: high / low transition\n",
    "#       8 bits: byte 3, with least significant bit first\n",
    "#       Final bit: reset to high\n",
    "\n",
    "#     Although the baud rate of the internal Harp clock is\n",
    "#     100 kHz, the Behavior board outputs the clock signal\n",
    "#     at a lower baud rate (typically 1 kHz), so it can be\n",
    "#     acquired by data acquisition systems with sample rates\n",
    "#     as low as 5 kHz.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     timestamps : np.array\n",
    "#         Float times in seconds for each clock line transition\n",
    "#         If the acquisition system outputs integer sample numbers\n",
    "#         for each event, divide by the sample rate to convert to seconds\n",
    "#     states : np.array\n",
    "#         States (1 or 0) for each clock line transition\n",
    "#     baud_rate : float\n",
    "#         The baud rate of the Harp clock signal\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     start_times : np.array\n",
    "#         Timestamps at which each second begins\n",
    "#     harp_times : np.array\n",
    "#         Harp clock times in seconds\n",
    "#     \"\"\"\n",
    "\n",
    "#     min_delta = 0.5  # seconds -- Harp clock events must always be\n",
    "#     # at least this far apart\n",
    "\n",
    "#     barcode_edges = get_barcode_edges(timestamps, min_delta)\n",
    "\n",
    "#     start_times = np.array([timestamps[edges[0]] for edges in barcode_edges])\n",
    "\n",
    "#     harp_times = np.array(\n",
    "#         [\n",
    "#             convert_barcode(\n",
    "#                 timestamps[edges[0] : edges[1]],\n",
    "#                 states[edges[0] : edges[1]],\n",
    "#                 baud_rate=baud_rate,\n",
    "#             )\n",
    "#             for edges in barcode_edges\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     # start_times_corrected, harp_times_corrected = remove_outliers(\n",
    "#     #     start_times, harp_times\n",
    "#     # )\n",
    "\n",
    "#     # return start_times_corrected, harp_times_corrected\n",
    "#     return start_times, harp_times\n",
    "\n",
    "\n",
    "# def get_barcode_edges(timestamps, min_delta):\n",
    "#     \"\"\"\n",
    "#     Returns the start and end indices of each barcode\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     timestamps : np.array\n",
    "#         Timestamps (ins seconds) of clock line events\n",
    "#         (high and low states)\n",
    "#     min_delta : int\n",
    "#         The minimum length between the end of one\n",
    "#         barcode and the start of the next\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     edges : list of tuples\n",
    "#         Contains the start and end indices of each barcode\n",
    "#     \"\"\"\n",
    "\n",
    "#     (splits,) = np.where(np.diff(timestamps) > min_delta)\n",
    "\n",
    "#     return list(zip(splits[:-1] + 1, splits[1:] + 1))\n",
    "\n",
    "\n",
    "# def convert_barcode(transition_times, states, baud_rate):\n",
    "#     \"\"\"\n",
    "#     Converts Harp clock barcode to a clock time in seconds\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     transition_times : np.array\n",
    "#         Times (in seconds) each clock line transition\n",
    "#     states : np.array\n",
    "#         states (1 or 0) for each clock line transition\n",
    "#     baud_rate : float\n",
    "#         The baud rate of the clock signal\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     harp_time : int\n",
    "#         Harp time in seconds for the current barcode\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     intervals = np.round(np.diff(transition_times * baud_rate)).astype(\"int\")\n",
    "\n",
    "#     barcode = np.concatenate(\n",
    "#         [np.ones((count,)) * state for state, count in zip(states[:-1], intervals)]\n",
    "#     ).astype(\"int\")\n",
    "\n",
    "#     val = np.concatenate(\n",
    "#         (np.arange(1, 9), np.arange(11, 19), np.arange(21, 29), np.arange(31, 39))\n",
    "#     )\n",
    "\n",
    "#     s = np.flip(barcode[val])\n",
    "#     harp_time = s.dot(2 ** np.arange(s.size)[::-1])\n",
    "\n",
    "#     return harp_time\n",
    "\n",
    "\n",
    "# def remove_outliers(start_times, harp_times):\n",
    "#     \"\"\"\n",
    "#     Removes outliers from the Harp clock times\n",
    "\n",
    "#     These outliers are caused by problems decoding\n",
    "#     the Harp clock signal, leading to consecutive times that\n",
    "#     do not increase by exactly 1. These will be removed from\n",
    "#     the array of Harp times, so they will not be used\n",
    "#     as anchor points during subsequent clock alignment.\n",
    "\n",
    "#     If the times jump to a new value and continue to\n",
    "#     increase by 1, either due to a reset of the Harp clock\n",
    "#     or a gap in the data, these will be ignored.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     start_times : np.array\n",
    "#         Harp clock start times in seconds\n",
    "#     harp_times : np.array\n",
    "#         Harp clock times in seconds\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     corrected_start_times : np.array\n",
    "#         Corrected Harp clock times in seconds\n",
    "#     corrected_harp_times : np.array\n",
    "#         Corrected Harp clock times in seconds\n",
    "#     \"\"\"\n",
    "\n",
    "#     original_indices = np.arange(len(harp_times))\n",
    "\n",
    "#     new_indices = np.concatenate(\n",
    "#         [\n",
    "#             sub_array\n",
    "#             for sub_array in np.split(\n",
    "#                 original_indices, np.where(np.diff(harp_times) != 1)[0] + 1\n",
    "#             )\n",
    "#             if len(sub_array) > 1\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     num_outliers = len(original_indices) - len(new_indices)\n",
    "\n",
    "#     if num_outliers > 0:\n",
    "#         warnings.warn(\n",
    "#             f\"{num_outliers} outlier{'s' if num_outliers > 1 else ''} \"\n",
    "#             + \"found in the decoded Harp clock. Removing...\"\n",
    "#         )\n",
    "\n",
    "#     return start_times[new_indices], harp_times[new_indices]\n",
    "\n",
    "# start_times, harp_times = decode_harp_clock(sorted_timestamps/1000, sorted_transitions, baud_rate=1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert hsfp time to harp time\n",
    "\n",
    "# def upsample_timestamps(timestamps, data_length, downsample_factor=1000):\n",
    "#     \"\"\"\n",
    "#     Upsamples the timestamp vector to match the length of the data vector.\n",
    "\n",
    "#     Parameters:\n",
    "#     timestamps (list or np.array): The downsampled timestamps (1 value for every 1000 data points).\n",
    "#     data_length (int): The length of the data vector.\n",
    "#     downsample_factor (int): The downsampling factor, default is 1000 (timestamps every 1000 data points).\n",
    "\n",
    "#     Returns:\n",
    "#     np.array: The upsampled timestamp vector.\n",
    "#     \"\"\"\n",
    "#     # Generate the original downsampled indices (one timestamp for every downsample_factor data points)\n",
    "#     original_indices = np.arange(0, data_length, downsample_factor)\n",
    "#     # Create an array of indices for the full data length\n",
    "#     full_indices = np.arange(data_length)\n",
    "#     # Perform linear interpolation to upsample the timestamps\n",
    "#     interpolation_function = interp1d(original_indices, timestamps, kind='linear', fill_value=\"extrapolate\")\n",
    "#     # Apply the interpolation function to get timestamps for each data point\n",
    "#     upsampled_timestamps = interpolation_function(full_indices)\n",
    "    \n",
    "#     return upsampled_timestamps\n",
    "\n",
    "# # Upsample the timestamps\n",
    "# hsfp_timestamps = upsample_timestamps(start_times, len(start_times)*1000, downsample_factor=1000)\n",
    "# harp_timestamps = upsample_timestamps(harp_times, len(harp_times)*1000, downsample_factor=1000)\n",
    "\n",
    "# # Convert each laser hsfp time to harp time\n",
    "\n",
    "# def convert_hsfp_to_harp_time(hsfp_timestamps, harp_timestamps, hsfp_time):\n",
    "#     \"\"\"\n",
    "#     Converts HSFP timestamps to Harp timestamps.\n",
    "#     Parameters:\n",
    "#     hsfp_timestamps (np.array): The HSFP timestamps.\n",
    "#     harp_timestamps (np.array): The Harp timestamps.\n",
    "#     hsfp_time (float): The HSFP time to convert.\n",
    "#     Returns:\n",
    "#     float: The Harp time.\n",
    "#     \"\"\"\n",
    "#     harp_time = np.zeros(len(hsfp_time))\n",
    "#     for i in range(len(hsfp_time)):\n",
    "#         # Find the index of the closest HSFP timestamp\n",
    "#         hsfp_index = np.searchsorted(hsfp_timestamps, hsfp_time[i])\n",
    "#         harp_time[i] = harp_timestamps[hsfp_index]\n",
    "#     return harp_time\n",
    "\n",
    "# # Convert each laser hsfp time to harp time\n",
    "# harp_time_405 = convert_hsfp_to_harp_time(hsfp_timestamps, harp_timestamps, time_405)\n",
    "# harp_time_445 = convert_hsfp_to_harp_time(hsfp_timestamps, harp_timestamps, time_445)\n",
    "# harp_time_473 = convert_hsfp_to_harp_time(hsfp_timestamps, harp_timestamps, time_473)\n",
    "# harp_time_514 = convert_hsfp_to_harp_time(hsfp_timestamps, harp_timestamps, time_514)\n",
    "# harp_time_560 = convert_hsfp_to_harp_time(hsfp_timestamps, harp_timestamps, time_560)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HSFPpreprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
